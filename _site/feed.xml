<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <generator uri="http://jekyllrb.com" version="3.8.5">Jekyll</generator>
  
  
  <link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2019-07-09T16:04:58+05:30</updated>
  <id>http://localhost:4000//</id>

  
    <title type="html">aartika rai</title>
  

  

  
    <author>
        <name>aartika</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Partially Supervised Object detection</title>
      
      
      <link href="http://localhost:4000/2019/06/11/cv-project-1/" rel="alternate" type="text/html" title="Partially Supervised Object detection" />
      
      <published>2019-06-11T00:21:36+05:30</published>
      <updated>2019-06-11T00:21:36+05:30</updated>
      <id>http://localhost:4000/2019/06/11/cv-project-1</id>
      <content type="html" xml:base="http://localhost:4000/2019/06/11/cv-project-1/">&lt;p&gt;This is a summary of my course project for Computer Vision at UMass. As I was looking for ideas for the project, I came across the paper ‘Learning to segment everything’ by Hu et. al. I had recently learnt about meta-learning which I found to be very exciting. In this paper, Hu et. al. are tackling the problem of obtaining expensive segmentation mask annotations. They demonstrate an apporach which allows them to learn to predict segmentation masks for novel classes. For these new classes, only a weaker form of supervision is available in the form of bounding boxes. Their approach still requires mask annotation for some classes. Thus, they call their formulation ‘partially supervised’ as the training data consists of subsets with full supervision and weak supervision.&lt;/p&gt;

&lt;p&gt;This ‘partially supervised’ paradigm, though requiring more supervision than an entirely-weakly supervised approach such as WSDNN discussed later, may actually be more pragmatic as it makes use of the already available mask annotations in the form of large scale datasets e.g. MS COCO, PASCAL VOC etc. while building the capability to generalize to new classes.&lt;/p&gt;

&lt;p&gt;For my part, I wondered whether the weak supervision could not be made weaker than bounding boxes. For the project, I modified the problem such that only image level classification labels are available as weak supervision. This problem statement, “Partially supervised object detection”, assumes bounding box annoatations for the fully supervised set and multiu-class labels for weakly supervised. Multi-class labels are nothing but a binary label for each class telling whether or not an object of that class appears in a given image.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:4000/assets/CV_poster.pdf&quot;&gt;Poster&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>aartika</name>
          
          
        </author>
      

      
        <category term="CV" />
      

      

      
        <summary type="html">This is a summary of my course project for Computer Vision at UMass. As I was looking for ideas for the project, I came across the paper ‘Learning to segment everything’ by Hu et. al. I had recently learnt about meta-learning which I found to be very exciting. In this paper, Hu et. al. are tackling the problem of obtaining expensive segmentation mask annotations. They demonstrate an apporach which allows them to learn to predict segmentation masks for novel classes. For these new classes, only a weaker form of supervision is available in the form of bounding boxes. Their approach still requires mask annotation for some classes. Thus, they call their formulation ‘partially supervised’ as the training data consists of subsets with full supervision and weak supervision.</summary>
      

      
      
    </entry>
  
  
</feed>
